# An√°lisis de Sentimientos para E-Commerce üåéüõí

Esta es una plataforma de an√°lisis de sentimientos dise√±ada para resolver el problema de la escasez de datos etiquetados en espa√±ol para el comercio electr√≥nico. Utiliza una Arquitectura H√≠brida que aprovecha modelos Transformers entrenados con datos globales (Ingl√©s) para realizar inferencias precisas en el mercado local (Espa√±ol).

## üöÄ Caracter√≠sticas Principales

Modelo SOTA: Utiliza xlm-roberta-base (multiling√ºe) ajustado con Transfer Learning.

Estrategia Cross-Lingual: Entrenado con +20,000 rese√±as de Amazon en Ingl√©s, pero capaz de procesar espa√±ol mediante una capa de traducci√≥n en tiempo real.

Alta Precisi√≥n: Accuracy del 89.08% validado en el conjunto de prueba.

Detecci√≥n de Matices: Clasificaci√≥n en 3 clases (Positivo, Neutro, Negativo) con l√≥gica de umbral para manejar la incertidumbre.

üõ†Ô∏è Arquitectura del Sistema

El proyecto sigue un flujo de datos h√≠brido para maximizar la calidad del an√°lisis sin requerir un dataset masivo en espa√±ol:

graph LR
    A[Usuario (Espa√±ol)] -->|Texto: 'Lleg√≥ roto'| B(Traductor ES->EN)
    B -->|Texto: 'Arrived broken'| C{Modelo XLM-RoBERTa}
    C -->|Logits| D[Clasificaci√≥n]
    D -->|Resultado| E[Negativo üò°]


Ingesta: Entrada de texto en Espa√±ol.

Adaptaci√≥n: Traducci√≥n autom√°tica al ingl√©s usando deep-translator.

Inferencia: El modelo Transformer (fine-tuned) procesa el texto en ingl√©s.

Salida: Etiqueta de sentimiento final.

üìÇ Estructura del Proyecto

El repositorio est√° organizado en 3 Notebooks principales que cubren el ciclo de vida del ML:

01_EDA_Limpieza.ipynb:

Ingesta del dataset Amazon Product Reviews (Ingl√©s).

Limpieza de texto (Regex) y normalizaci√≥n.

Divisi√≥n estratificada (80/20) para manejar el desbalance de clases.

02_Entrenamiento.ipynb:

Tokenizaci√≥n con AutoTokenizer (XLM-R).

Fine-tuning usando la API Trainer de Hugging Face.

Persistencia del modelo y tokenizador.

03_Evaluacion_Inferencia.ipynb:

C√°lculo de m√©tricas (Matriz de Confusi√≥n, F1-Score).

Implementaci√≥n de la funci√≥n predecir_sentimiento() con traducci√≥n integrada.

üíª Instalaci√≥n y Requisitos

Este proyecto fue desarrollado en Google Colab. Para ejecutarlo localmente, necesitas las siguientes dependencias:

pip install torch transformers accelerate datasets scikit-learn pandas deep-translator emoji


ü§ñ Ejemplo de Uso (Inferencia)

Una vez cargado el modelo entrenado, puedes realizar predicciones en espa√±ol as√≠:

from transformers import AutoTokenizer, AutoModelForSequenceClassification
from deep_translator import GoogleTranslator
import torch

# 1. Cargar Modelo
MODEL_PATH = "./modelos/sentimiento_xlmroberta_v1"
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)

# 2. Funci√≥n de Predicci√≥n H√≠brida
def predecir(texto_espanol):
    # Traducir
    traductor = GoogleTranslator(source='es', target='en')
    texto_en = traductor.translate(texto_espanol)
    
    # Tokenizar e Inferir
    inputs = tokenizer(texto_en, return_tensors="pt", truncation=True, max_length=128)
    with torch.no_grad():
        logits = model(**inputs).logits
    
    # Post-procesamiento
    pred_idx = logits.argmax(-1).item()
    etiquetas = {0: "Negativo üî¥", 1: "Neutro üü°", 2: "Positivo üü¢"}
    
    return etiquetas[pred_idx]

# 3. Prueba
print(predecir("El producto es excelente, lleg√≥ muy r√°pido."))
# Salida: Positivo üü¢


üìä Resultados Obtenidos

M√©trica

Valor

Descripci√≥n

Accuracy

89.08%

Exactitud global del modelo.

F1-Score

0.8456

Promedio ponderado (Weighted).

Loss

< 0.40

Convergencia estable en 1 √©poca.

Nota: Se observ√≥ un desaf√≠o en la detecci√≥n de la clase "Neutra" debido al desbalance del dataset original (<2% de muestras neutras). Se recomienda usar un umbral de confianza para mejorar esto en producci√≥n.

üë• Autores (Grupo 3)

Proyecto desarrollado para la Maestr√≠a en Inteligencia de Negocios y Ciencia de Datos - UEES.

Liz Eliana Castillo Zamora

Pablo Mauricio Castro Hinostroza

Erick Sebasti√°n Rivas

√Ångel Israel Romero Medina

Made with ‚ù§Ô∏è  by Group 3.
